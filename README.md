<div align="center">

<h1>StyleDrive: Towards Driving-Style Aware Benchmarking of End-To-End Autonomous Driving</h1>

</div>

## Introduction

We introduce the first large-scale real-world dataset with fine-grained driving preference annotations and a benchmark for evaluating personalized end-to-end autonomous driving, enabling human-aligned behavior through a combination of static and dynamic scene understanding, VLM-generated subjective labels, and human-in-the-loop validation.

This repo is the StyleDrive benchmark codebase.

## Getting Started

- [Getting started from NAVSIM environment preparation](https://github.com/autonomousvision/navsim?tab=readme-ov-file#getting-started-)
- [Preparation of DiffusionDrive environment](docs/install.md)
- [Preparation of Style Drive data](docs/train_eval.md)
- [Training and Evaluation](docs/train_eval.md)

## Acknowledgement

DiffusionDrive is greatly inspired by the following outstanding contributions to the open-source community: [NAVSIM](https://github.com/autonomousvision/navsim), [Transfuser](https://github.com/autonomousvision/transfuser), [DiffusionDrive](https://github.com/hustvl/DiffusionDrive).
